---
title: "Continuous Variables"
subtitle: "Measures and Basic Tests"
author: "Frances Hung"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(tidyverse)
library(Gmisc)
library(Hmisc)
library(gtsummary)
library(broom)
library(medicaldata)
library(PASWR2)
#library(flextable)
```

Today, we will briefly go over common measures used to describe continuous data:

-   Centrality measures (mean, median, mode)
-   Measures of spread (standard deviation, range, interquartile range)

Statistical models will often make inferences on centrality measures, and these models will also need measures of spread as input. 

After this, we will cover basic ways of comparing continuous measures between groups differentiated by a characteristic. Some of these concepts (t-tests, correlation) are also applicable to and important for understanding discrete data as well.

## Review: Data Cleaning and Visualization

Since today's lecture is focused on continuous variables, let's clean and visualize a dataset that we can use for the remainder of the lecture. For this lecture and the next few, we'll use a dataset called `indo_rct` which has data from a randomized control trial (RCT) on using indomethacin for prevention of post-ERCP pancreatitis. 

For today's outcome, we'll focus on the continuous measure `risk` (a patient's estimated risk score). Other variables that we'll need for today are:

- age
- pep (risk factor: previous post-ERCP pancreatitis)
- psphinc (risk factor: whether pancreatic sphincteromy was performed)

We start by getting a general sense of the data. Let's take a peek.

```{r head-indo, options}
indo_rct_day3 <- indo_rct %>%
  select(risk, age, pep, psphinc)

head(indo_rct_day3)

# the categorical variables are already in factor form, so no need to modify inside summary command
summary(indo_rct_day3)
```
Notice that all categorical variables have a number, underscore, no/yes for a value. This is redundant information, so we can get rid of the no/yes.

```{r clean, options}
indo_rct_day3_clean <- indo_rct_day3 %>%
  mutate(across(c(pep, psphinc),
                ~str_remove(.x, "(.*)_")))

head(indo_rct_day3_clean)
```

### Exercises: Data Visualization

1. Recreate the boxplot below.
```{r indo-rct, options}
indo_rct_day3_clean %>%
  ggplot(aes(x=pep, y=risk)) +
  geom_boxplot()
```

2. Fit a dotplot with age on the x-axis and risk score on the y-axis.

```{r dotplot, options}
indo_rct_day3_clean %>%
  ggplot(aes(x=age, y=risk)) +
  geom_point()
```

## Centrality Measures

The goal of statistics is to simplify data into easily interpretable numbers. The ones we often use to describe "average" behavior include the mean, median, and mode.

The **mean** of a continuous variable is the sum of continuous values from the sample divided by the sample size. 

The **median** of a continuous variable is the number at the 

The **mode** of a continuous variable may not be as meaningful as the other two centrality measures.



### Exercises: Measures

1. Calculate the mean and median of risk score by pep and psphinc using tidyverse.

```{r centrality-ex, options}
indo_rct_day3_clean %>%
  group_by(pep, psphinc) %>%
  summarise(mean_risk = mean(risk),
            median_risk = median(risk))
```

## Group comparisons of events

We can talk about basic ways of comparing continuous centrality measures among different groups, now that we've defined what centrality and spread measures are. This is our first foray into statistical tests. This workshop is not meant to give statistical background on these tests, so stay tuned for the in-person workshop (or consult with a statistician) before using these tests in research projects.

Below are three different ways of visualizing or testing continuous centrality measure differences among groups.

-   Correlation
-   T-test
-   Wilcoxon

More sophisticated ways of testing continuous measure differences between groups (like linear regression, adjusting for other variables) will be introduced later.

## Correlation

Correlation is a rough measure of how associated two variables are. Most correlation measures range from -1 to 1, where a correlation of 1 means as one variable becomes more positive, the other does as well. A correlation of -1 means that as one variable becomes more positive, the other becomes more negative, and a correlation of 0 means no relationship.

The code below calculates the Pearson correlation measure, which assumes a linear relationship between continuous variables, as well as the Spearman correlation, which doesn't.

We can use correlation to look at event-related variables as well, as we'll see in our next lecture.

```{r cor, options}
cor(indo_rct_day3_clean$risk, indo_rct_day3_clean$age,
    method = "pearson")

cor(indo_rct_day3_clean$risk, indo_rct_day3_clean$age,
    method = "spearman")
```

## T-test (Parametric)

The t-test approximates how likely we'd see the observed difference in means, assuming that the true means of the groups are actually the same. A small p-value means that there is evidence that the true means of the groups are different.

It assumes that if we took many samples from the two group populations, the resulting sample means would be normally distributed (bell-shaped). This usually holds if we have a large enough sample size. 

There are several variations of t-test, depending on what assumptions we make. Today, we go over the case where the two groups have unknown, different population variances (most common).

We can either supply the raw tidy data to a t-test function, or we can supply the means, standard deviations, and counts of each group sample to a summarized t-test function.

### From Raw Data

```{r raw-t-test, options}
t.test(indo_rct_day3_clean$risk ~ indo_rct_day3_clean$pep, #alternative hypothesis: mean risk differs by pep status
       alternative = "two.sided", #two-sided alternative hypothesis
       mu = 0, #null hypothesis: difference is 0
       paired = FALSE, #group observations are not paired 
       var.equal = FALSE, #variances are not equal
       conf.level = 0.95) #alpha (type-I error) is 0.05
```

### From Means and Sample Variances

```{r paswr-t-test, options}

#--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---
# find mean and SD risk by pep group
#--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---
sumStatsPepRisk <- indo_rct_day3_clean %>%
  group_by(pep) %>%
  summarise(meanRisk = mean(risk),
            sdRisk = sd(risk),
            countRisk = n())


#--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---
# input mean and SD by pep group into summarized t-test
#--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---
tsum.test(mean.x = sumStatsPepRisk %>% 
            filter(pep == "yes") %>%
            .$meanRisk,
          s.x = sumStatsPepRisk %>% 
            filter(pep == "yes") %>%
            .$sdRisk,
          n.x = sumStatsPepRisk %>% 
            filter(pep == "yes") %>%
            .$countRisk,
          mean.y = sumStatsPepRisk %>% 
            filter(pep == "no") %>%
            .$meanRisk,
          s.y = sumStatsPepRisk %>% 
            filter(pep == "no") %>%
            .$sdRisk,
          n.y = sumStatsPepRisk %>% 
            filter(pep == "no") %>%
            .$countRisk,
          alternative = "two.sided", #two-sided alternative hypothesis
          mu = 0, #null hypothesis: difference is 0
          var.equal = FALSE, #variances are not equal
          conf.level = 0.95) #alpha (type-I error) is 0.05
```
### Changing Parameters

In both the t-test and summarized t-test functions, we can change parameter values to suit our problem of interest:

- alternative: we can specify this to be "less" or "greater" if our alternative hypothesis is one-sided
- conf.level: if our chosen alpha type-I level is something other than the default 0.05 (conf.level=0.95), we specify here
- paired: if we want to use a paired t-test, we set this to TRUE

## Wilcoxon (Non-parametric)

Similarly to the t-test, the chi-squared test approximates how likely we'd see the observed difference in proportions, assuming that the true **medians** of the groups are actually the same. A small p-value means that there is evidence that the true medians of the groups are different.

It doesn't have the same normality assumption as the t-test, making it good for small samples where the assumption may not hold. However, the t-test is more powerful (has a higher ability to correctly reject the null hypothesis if the alternative is in fact true) than the Wilcoxon under correct normality assumptions. The mean rather than the median is often of more interest to researchers, since it is what is available for interpretation when we do standard regression (our next section).

```{r wilcoxon, options}
wilcox.test(indo_rct_day3_clean$risk ~ indo_rct_day3_clean$pep)
```

### Exercises: 2-Group Comparison Tests

We'll see if mean or median age is different between pep groups.

1. Use `group_by` and `summarise` to find the mean and median age for patients with and without pep.
2. Use a two-sided t-test to test if mean age differs between patients with and without pep.
3. Use a one-sided t-test to test if mean age is lower in patients with compared to patients without pep.

```{r answers-comparison-tests, options}
t.test(indo_rct_day3_clean$age ~ indo_rct_day3_clean$pep, #alternative hypothesis: mean risk differs by pep status
       alternative = "two.sided", #two-sided alternative hypothesis
       mu = 0, #null hypothesis: difference is 0
       paired = FALSE, #group observations are not paired 
       var.equal = FALSE, #variances are not equal
       conf.level = 0.95) #alpha (type-I error) is 0.05

t.test(indo_rct_day3_clean$age ~ indo_rct_day3_clean$pep, #alternative hypothesis: mean risk differs by pep status
       alternative = "greater", #two-sided alternative hypothesis
       mu = 0, #null hypothesis: difference is 0
       paired = FALSE, #group observations are not paired 
       var.equal = FALSE, #variances are not equal
       conf.level = 0.95) #alpha (type-I error) is 0.05
```
